# AI学習用データ生成計画 (Sim2Real：シミュレーションから現実へ)

本プロジェクトの目的は、実際の遺跡発掘現場で使用可能な「土器修復AI」を開発することです。
そのために、Blender（RBDLab）を「リアルな教師データ生成工場」として再定義します。

## 1. データの多様性とリアリティ (Reality Gap の解消)
現場の土器は「綺麗」でも「完全」でもありません。AIを実戦で使えるようにするため、以下の **3つの「意地悪」** をデータに加えます。

### A. 形状の自動生成 (Procedural Generation)
1つのモデル（Lathe_Pot）だけではAIが「その形」しか覚えられません。スクリプトで無限のバリエーションを作ります。
*   **パラメータ**: 高さ、底の半径、胴体の膨らみ、首のくびれ、口の広がり。
*   **種類**: 壺型、皿型、深鉢型などをランダムに生成し続けます。

### B. 経年劣化の再現 (Simulating Wear & Tear)
「割れた直後」の鋭利な断面は、数千年の土中で丸くなります。
1.  **摩耗 (Erosion)**:
    *   破片のエッジ（角）に対して `Bevel` や `Smooth` 処理をかけ、**角を丸く**します。
    *   これにより「角が取れた破片」をAIに見せることができます。
2.  **欠損 (Missing Parts)**:
    *   発掘ですべてのパーツが揃うことは稀です。
    *   学習データを書き出す際、ランダムに **10%〜30%の破片を「消去」** します。
    *   「隣のピースがない」状態でも、断面を正しく認識できるかを訓練します。
3.  **劣化ノイズ (Surface Noise)**:
    *   スキャンデータ特有の「微細な凹凸」を再現するため、メッシュ全体に微小なノイズを乗せます。

## 2. データ形式とラベル定義 (Data Encoding)

Google Colab等のAI環境に渡すためのデータ仕様です。

### Q. 容量は大丈夫？
**A. 全く問題ありません。**
画像データ（数MB）と違い、「点群データ」は座標のテキスト（数値）だけなので非常に軽量です。
*   1つの破片 ≒ 2048個の点 ≒ **約 25KB**
*   1万個の破片データでも **約 250MB** 程度。Google Colabの無料枠でも余裕で扱えます。

### C. 接続関係の学習 (Adjacency Learning)
「どの破片とどの破片がつながるか」も学習します。
1.  **正解リスト (Ground Truth)**:
    *   Blenderで割った瞬間、お互いに接していた破片のペアを記録します。
    *   `adjacency.json` として `{"Shard_001": ["Shard_005", "Shard_012"]}` のように保存します。
2.  **ペア判定AI**:
    *   2つの破片の断面データを入力し、「これらはつながる確率が高いか？」を判定させます。

## 2. データ形式とラベル定義 (Data Encoding)

Google Colab等のAI環境に渡すためのデータ仕様です。

### Q. 容量は大丈夫？
**A. 全く問題ありません。**
画像データ（数MB）と違い、「点群データ」は座標のテキスト（数値）だけなので非常に軽量です。
*   1つの破片 ≒ 2048個の点 ≒ **約 25KB**
*   1万個の破片データでも **約 250MB** 程度。Google Colabの無料枠でも余裕で扱えます。

### Q. 「ラベル」とは？ 
AIに教える「正解」のことです。今回は**2種類の正解**を教えます。

**① 点ごとの正解 (Segmentation):**
各点が「断面かどうか」を当てる問題。

| ラベル値 | 意味 | 判定方法 (Blender側) |
| :--- | :--- | :--- |
| **0** | **Original Surface (元の表面)** | RBDLabの `Inner Material` が**ない**面。 |
| **1** | **Fracture Surface (断面)** | RBDLabの `Inner Material` が**ある**面。 |

**② ペアごとの正解 (Matching):**
2つの破片が「つながるかどうか」を当てる問題。
*   **Adjacency List**: `connected_pairs.csv` (例: `Shard_A, Shard_B, 1` = つながる)

## 3. 実践ロードマップ

### Phase 1: データ生成パイプラインの構築
1.  **多種生成スクリプト**: ボタン一つで違う形の土器が出てくるスクリプトを作る。
2.  **劣化加工スクリプト**: 割れた後の破片の角を丸める処理を追加する。
3.  **点群書き出しスクリプト**: 破片をスキャンし、`.h5` または `.ply` 形式（点群＋ラベル0/1）で保存する機能を作る。

### Phase 2: AIモデルの選定と学習
1.  **モデル**: **PointNet++** または **DGCNN** (Dynamic Graph CNN) を使用。
    *   不規則な形の3Dデータを扱うのに特化したAIです。
2.  **環境**: Google Colab。
3.  **テスト**: 「見たことのない形の土器」をテストデータとして、正解率（断面を正しく赤く塗れるか）を検証する。

## 4. 学習環境とスケジュール (Google Colab想定)

### 4.1 データセット量
- **プロトタイプ**: 100 〜 500 土器ケース（各土器を30〜50個に破壊）
- **本番**: 1,000 〜 5,000 土器ケース
- ※プロシージャル生成により、Blenderを回し続けることで無限に生成可能。

### 4.2 学習時間（目安）
- **データ生成**: Blender MCPでの自動生成で、1,000ケースあたり約5〜10時間（並列化なしの場合）。
- **AI学習 (Google Colab)**: 
    - 1エポックあたり約5〜15分。
    - フル訓練（100〜200エポック）で約12〜24時間を想定。
    - Google Colab ProのA100/V100 GPUを使用することで短縮可能。

## 5. 断面分割アルゴリズムの詳細 (Facet Segmentation Logic)

**問題**: 単に「ここが断面だ(赤色)」と分かるだけでは不十分。「この破片には3つの別々の断面がある」と区別し、それぞれの中心を特定する必要がある。

### 5.1 アルゴリズム: 多数決＆空間平滑化 (Majority-Vote & Smoothing)
1.  **入力**: 断面用マテリアルが割り当てられた面。
2.  **最近接ラベル付与**: 各面の中心から、Frame 1（密着時）において最も近い他の破片のIDを取得。
3.  **ノイズ除去（ smoothing）**:
    - 単一のポリゴンが誤差で誤ったIDを持っていても、周囲の多数決で修正される。
    - `Counter(neighbor_labels).most_common(1)` によるラベル伝播。
4.  **最終統合**: 同じラベルを持ち、物理的に接続されている面を「1つの断面（Facet）」として確定。
5.  **出力**: Facet ID, 接合相手の破片ID, 面の重心、法線ベクトル。

### 4.2 正解データとしての利用
*   **Facet Matching**:
    *   AIには「破片AのFacet_0」と「破片BのFacet_3」がつながる、という細かい粒度の正解データを教える。
    *   これにより、再構築時に「破片のどっち側につなげればいいか」まで推論可能になる。
